{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f83cce",
   "metadata": {},
   "source": [
    "\n",
    "# 03_dataset_and_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6944eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5d89e",
   "metadata": {},
   "source": [
    "Training transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddaa58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),          # ResNet-50 input size\n",
    "    transforms.RandomHorizontalFlip(),       # augmentation\n",
    "    transforms.RandomRotation(10),            # augmentation\n",
    "    transforms.ToTensor(),                    # convert to tensor\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],           # ImageNet mean\n",
    "        std=[0.229, 0.224, 0.225]              # ImageNet std\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aded23b",
   "metadata": {},
   "source": [
    "#Validation transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee17c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41395dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISICSkinDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        csv_file   : processed CSV (train or val)\n",
    "        image_dir  : directory containing raw images\n",
    "        transform  : torchvision transforms\n",
    "        \"\"\"\n",
    "        nb_dir = Path.cwd()\n",
    "        project_root = nb_dir if (nb_dir / 'data').exists() else nb_dir.parent\n",
    "        csv_file = pd.read_csv(str(project_root / 'data' / 'processed' / 'train' / 'train_binary.csv'))\n",
    "        image_dir = Path(project_root / 'data' / 'raw' / 'train' / 'images_train')\n",
    "\n",
    "        self.df = csv_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Total number of samples\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get one row from processed CSV\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Image ID from CSV\n",
    "        image_id = row[\"isic_id\"]\n",
    "\n",
    "        # Label (already binary: 0 or 1)\n",
    "        label = torch.tensor(row[\"label\"], dtype=torch.long)\n",
    "\n",
    "        # Construct image path\n",
    "        image_path = f\"{self.image_dir}/{image_id}.jpg\"\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transforms (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a399c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd().parent\n",
    "\n",
    "train_dataset = ISICSkinDataset(\n",
    "    csv_file=project_root/\"data/processed/train/train_binary.csv\",\n",
    "    image_dir=project_root/\"data/raw/train/images_train\",\n",
    "    transform=train_transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6aa54846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "img, lbl = train_dataset[0]\n",
    "print(img.shape, lbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450ce01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd492cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fa81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e666762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
